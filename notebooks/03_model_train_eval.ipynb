{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47efc480-f24a-46c7-9ed2-5fee504c2258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " 6,\n",
       " ['bh_mass', 'bh_acc', 'stellar_mass', 'sfr', 'halo_mass', 'vel_disp'],\n",
       " {'T_IN': 8,\n",
       "  'HORIZONS': [1, 3, 5],\n",
       "  'BATCH': 256,\n",
       "  'HIDDEN': 128,\n",
       "  'LAYERS': 2,\n",
       "  'DROPOUT': 0.1,\n",
       "  'EPOCHS': 100,\n",
       "  'LR': 0.001,\n",
       "  'WD': 1e-05,\n",
       "  'GRAD_CLIP': 1.0,\n",
       "  'PATIENCE': 12,\n",
       "  'SEED': 1337})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR   = Path(\"../data/processed\")\n",
    "FIG_DIR    = Path(\"../reports/figures\"); FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR  = Path(\"../reports/tables\");  TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR  = Path(\"../models\");          MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_FP  = DATA_DIR / \"train.parquet\"\n",
    "VAL_FP    = DATA_DIR / \"val.parquet\"\n",
    "TEST_FP   = DATA_DIR / \"test.parquet\"\n",
    "STATS_CSV = DATA_DIR / \"standardization_stats.csv\"\n",
    "assert TRAIN_FP.exists() and VAL_FP.exists() and TEST_FP.exists(), \"missing processed parquet files; run preprocessing.\"\n",
    "assert STATS_CSV.exists(), \"missing standardization_stats.csv; run preprocessing.\"\n",
    "\n",
    "FEATURES = [\"bh_mass\",\"bh_acc\",\"stellar_mass\",\"sfr\",\"halo_mass\",\"vel_disp\"]\n",
    "NAME_MAP = {\n",
    "    \"bh_mass\":\"Black Hole Mass\",\n",
    "    \"bh_acc\":\"BH Accretion Rate\",\n",
    "    \"stellar_mass\":\"Stellar Mass\",\n",
    "    \"sfr\":\"Star Formation Rate\",\n",
    "    \"halo_mass\":\"Halo Mass\",\n",
    "    \"vel_disp\":\"Velocity Dispersion\",\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (7.5,5.2),\n",
    "    \"axes.titlesize\": 15,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"legend.fontsize\": 11\n",
    "})\n",
    "\n",
    "stats_df = pd.read_csv(STATS_CSV, index_col=0)\n",
    "STATS = {k: {\"mean\": float(stats_df.loc[k,\"mean\"]), \"std\": float(stats_df.loc[k,\"std\"])} for k in stats_df.index}\n",
    "\n",
    "CFG = {\n",
    "    \"T_IN\": 8,\n",
    "    \"HORIZONS\": [1,3,5],\n",
    "    \"BATCH\": 256,\n",
    "    \"HIDDEN\": 128,\n",
    "    \"LAYERS\": 2,\n",
    "    \"DROPOUT\": 0.10,\n",
    "    \"EPOCHS\": 100,\n",
    "    \"LR\": 1e-3,\n",
    "    \"WD\": 1e-5,\n",
    "    \"GRAD_CLIP\": 1.0,\n",
    "    \"PATIENCE\": 12,\n",
    "    \"SEED\": SEED,\n",
    "}\n",
    "\n",
    "DEVICE, len(FEATURES), list(stats_df.index), CFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3108474-a56c-4263-8c0e-8049d77019a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 5193 samples\n",
      "val: 1112 samples\n",
      "test: 1107 samples\n",
      "Input shape: torch.Size([256, 8, 6]) Target shape: torch.Size([256, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "class BHTimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Black Hole Evolution dataset for sequence modeling.\n",
    "    Produces input sequence (T_IN snapshots) and targets at given horizons.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, features, horizons, stats, t_in):\n",
    "        self.df = df.copy()\n",
    "        self.features = features\n",
    "        self.horizons = horizons\n",
    "        self.stats = stats\n",
    "        self.t_in = t_in\n",
    "\n",
    "        for f in self.features:\n",
    "            mu, sigma = stats[f][\"mean\"], stats[f][\"std\"]\n",
    "            self.df[f] = (self.df[f] - mu) / sigma\n",
    "\n",
    "        # group by subhalo\n",
    "        self.groups = [g for _, g in self.df.groupby(\"subhalo_id\")]\n",
    "\n",
    "        self.samples = []\n",
    "        for g in self.groups:\n",
    "            snaps = g[\"snapshot\"].to_numpy()\n",
    "            for i in range(len(snaps) - t_in - max(horizons) + 1):\n",
    "                x_idx = slice(i, i + t_in)\n",
    "                y_idx = [i + t_in - 1 + h for h in horizons]\n",
    "                if y_idx[-1] < len(snaps):\n",
    "                    self.samples.append((g.iloc[x_idx], g.iloc[y_idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_df, y_df = self.samples[idx]\n",
    "        x = x_df[self.features].to_numpy(dtype=np.float32)\n",
    "        y = np.stack([y_df[self.features].to_numpy(dtype=np.float32) for y_df in [y_df]], axis=0)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y.squeeze(0))\n",
    "\n",
    "\n",
    "def make_loaders(train_fp, val_fp, test_fp, features, horizons, stats, t_in, batch):\n",
    "    train = pd.read_parquet(train_fp)\n",
    "    val   = pd.read_parquet(val_fp)\n",
    "    test  = pd.read_parquet(test_fp)\n",
    "\n",
    "    dsets = {\n",
    "        \"train\": BHTimeSeriesDataset(train, features, horizons, stats, t_in),\n",
    "        \"val\":   BHTimeSeriesDataset(val, features, horizons, stats, t_in),\n",
    "        \"test\":  BHTimeSeriesDataset(test, features, horizons, stats, t_in),\n",
    "    }\n",
    "\n",
    "    loaders = {\n",
    "        k: DataLoader(v, batch_size=batch, shuffle=(k==\"train\"), drop_last=True)\n",
    "        for k,v in dsets.items()\n",
    "    }\n",
    "    return dsets, loaders\n",
    "\n",
    "\n",
    "dsets, loaders = make_loaders(\n",
    "    TRAIN_FP, VAL_FP, TEST_FP,\n",
    "    FEATURES, CFG[\"HORIZONS\"], STATS, CFG[\"T_IN\"], CFG[\"BATCH\"]\n",
    ")\n",
    "\n",
    "for k,v in dsets.items():\n",
    "    print(f\"{k}: {len(v)} samples\")\n",
    "\n",
    "batch_x, batch_y = next(iter(loaders[\"train\"]))\n",
    "print(\"Input shape:\", batch_x.shape, \"Target shape:\", batch_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667c01f2-b237-4284-aaf5-ae90f31b6dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMForecaster | params: 220,562 | device: cpu\n"
     ]
    }
   ],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=128, layers=2, dropout=0.1, horizons=3, out_dim=6):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            dropout=dropout if layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, horizons * out_dim),\n",
    "        )\n",
    "        self.horizons = horizons\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T_in, F]\n",
    "        _, (hn, _) = self.lstm(x)     \n",
    "        h = hn[-1]                    \n",
    "        y = self.head(h)              \n",
    "        y = y.view(-1, self.horizons, self.out_dim)  \n",
    "        return y\n",
    "\n",
    "model = LSTMForecaster(\n",
    "    in_dim=len(FEATURES),\n",
    "    hidden=CFG[\"HIDDEN\"],\n",
    "    layers=CFG[\"LAYERS\"],\n",
    "    dropout=CFG[\"DROPOUT\"],\n",
    "    horizons=len(CFG[\"HORIZONS\"]),\n",
    "    out_dim=len(FEATURES),\n",
    ").to(DEVICE)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: LSTMForecaster | params: {n_params:,} | device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ee36e4-01ab-4a43-b8bc-b7c4b1b67633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BHs: 2000, Val BHs: 500\n",
      "Train rows: 29931, Val rows: 7481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_CSV = \"../data/black_hole_evolution_tng100.csv\"\n",
    "\n",
    "if not Path(OUT_CSV).exists():\n",
    "    raise FileNotFoundError(f\"Processed dataset not found: {OUT_CSV}. \"\n",
    "                            \"Run the preprocessing notebook first.\")\n",
    "\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "\n",
    "all_ids = df[\"subhalo_id\"].unique()\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    all_ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df[\"subhalo_id\"].isin(train_ids)].reset_index(drop=True)\n",
    "val_df   = df[df[\"subhalo_id\"].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train BHs: {len(train_ids)}, Val BHs: {len(val_ids)}\")\n",
    "print(f\"Train rows: {len(train_df)}, Val rows: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6f969b-8bda-47d5-9ff7-44c0534c3e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train 1.18640 | Val 0.51763 | LR 1.00e-03  [*]\n",
      "Epoch 002 | Train 0.73178 | Val 0.41406 | LR 1.00e-03  [*]\n",
      "Epoch 003 | Train 0.57950 | Val 0.38757 | LR 1.00e-03  [*]\n",
      "Epoch 004 | Train 0.51872 | Val 0.33042 | LR 1.00e-03  [*]\n",
      "Epoch 005 | Train 0.49525 | Val 0.31351 | LR 1.00e-03  [*]\n",
      "Epoch 006 | Train 0.46796 | Val 0.30968 | LR 1.00e-03  [*]\n",
      "Epoch 007 | Train 0.44961 | Val 0.31010 | LR 1.00e-03\n",
      "Epoch 008 | Train 0.42623 | Val 0.27826 | LR 1.00e-03  [*]\n",
      "Epoch 009 | Train 0.41541 | Val 0.29092 | LR 1.00e-03\n",
      "Epoch 010 | Train 0.40129 | Val 0.30047 | LR 1.00e-03\n",
      "Epoch 011 | Train 0.39719 | Val 0.29348 | LR 1.00e-03\n",
      "Epoch 012 | Train 0.38667 | Val 0.30301 | LR 1.00e-03\n",
      "Epoch 013 | Train 0.38329 | Val 0.29396 | LR 5.00e-04\n",
      "Epoch 014 | Train 0.36608 | Val 0.27748 | LR 5.00e-04  [*]\n",
      "Epoch 015 | Train 0.36115 | Val 0.27544 | LR 5.00e-04  [*]\n",
      "Epoch 016 | Train 0.35560 | Val 0.27984 | LR 5.00e-04\n",
      "Epoch 017 | Train 0.35816 | Val 0.29175 | LR 5.00e-04\n",
      "Epoch 018 | Train 0.34696 | Val 0.27509 | LR 5.00e-04  [*]\n",
      "Epoch 019 | Train 0.34513 | Val 0.29105 | LR 5.00e-04\n",
      "Epoch 020 | Train 0.33732 | Val 0.28785 | LR 5.00e-04\n",
      "Epoch 021 | Train 0.33543 | Val 0.28751 | LR 5.00e-04\n",
      "Epoch 022 | Train 0.32666 | Val 0.30431 | LR 5.00e-04\n",
      "Epoch 023 | Train 0.32687 | Val 0.29771 | LR 2.50e-04\n",
      "Epoch 024 | Train 0.32239 | Val 0.28512 | LR 2.50e-04\n",
      "Epoch 025 | Train 0.31861 | Val 0.29058 | LR 2.50e-04\n",
      "Epoch 026 | Train 0.31404 | Val 0.28915 | LR 2.50e-04\n",
      "Epoch 027 | Train 0.31211 | Val 0.30073 | LR 2.50e-04\n",
      "Epoch 028 | Train 0.30824 | Val 0.29442 | LR 1.25e-04\n",
      "Epoch 029 | Train 0.30349 | Val 0.29826 | LR 1.25e-04\n",
      "Epoch 030 | Train 0.30409 | Val 0.30362 | LR 1.25e-04\n",
      "Early stopping at epoch 30 (no val improvement for 12 epochs).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/lstm_blackhole_best.pt', 0.275090250948156)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "assert 'BHTimeSeriesDataset' in globals(), \"Run Cell 2 first to define BHTimeSeriesDataset.\"\n",
    "\n",
    "dtr = DataLoader(\n",
    "    BHTimeSeriesDataset(train_df, FEATURES, CFG[\"HORIZONS\"], STATS, CFG[\"T_IN\"]),\n",
    "    batch_size=CFG[\"BATCH\"], shuffle=True, drop_last=False\n",
    ")\n",
    "dva = DataLoader(\n",
    "    BHTimeSeriesDataset(val_df, FEATURES, CFG[\"HORIZONS\"], STATS, CFG[\"T_IN\"]),\n",
    "    batch_size=CFG[\"BATCH\"], shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "\n",
    "def run_epoch(loader, train_mode=True):\n",
    "    model.train() if train_mode else model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    with torch.set_grad_enabled(train_mode):\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)            \n",
    "            yb = yb.to(DEVICE)            \n",
    "            if train_mode:\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "            yp = model(xb)                \n",
    "            loss = nn.functional.mse_loss(yp, yb)\n",
    "            if train_mode:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), CFG[\"GRAD_CLIP\"])\n",
    "                opt.step()\n",
    "            bs = xb.size(0)\n",
    "            total += loss.item() * bs\n",
    "            n += bs\n",
    "    return total / max(n, 1)\n",
    "\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=CFG[\"LR\"], weight_decay=CFG[\"WD\"])\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=4, verbose=False)\n",
    "\n",
    "best_val   = float(\"inf\")\n",
    "best_path  = MODEL_DIR / \"lstm_blackhole_best.pt\"\n",
    "history    = {\"epoch\": [], \"train\": [], \"val\": [], \"lr\": []}\n",
    "pat_count  = 0\n",
    "\n",
    "for epoch in range(1, CFG[\"EPOCHS\"] + 1):\n",
    "    tr_loss = run_epoch(dtr, train_mode=True)\n",
    "    va_loss = run_epoch(dva, train_mode=False)\n",
    "    sched.step(va_loss)\n",
    "\n",
    "    \n",
    "    improved = va_loss < best_val - 1e-6\n",
    "    if improved:\n",
    "        best_val = va_loss\n",
    "        pat_count = 0\n",
    "        torch.save(\n",
    "            {\"model\": model.state_dict(),\n",
    "             \"config\": {\"T_IN\": CFG[\"T_IN\"], \"HORIZONS\": CFG[\"HORIZONS\"], \"FEATURES\": FEATURES}},\n",
    "            best_path\n",
    "        )\n",
    "    else:\n",
    "        pat_count += 1\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train\"].append(tr_loss)\n",
    "    history[\"val\"].append(va_loss)\n",
    "    history[\"lr\"].append(opt.param_groups[0][\"lr\"])\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Train {tr_loss:.5f} | Val {va_loss:.5f} | LR {opt.param_groups[0]['lr']:.2e}\"\n",
    "          + (\"  [*]\" if improved else \"\"))\n",
    "\n",
    "    if pat_count >= CFG[\"PATIENCE\"]:\n",
    "        print(f\"Early stopping at epoch {epoch} (no val improvement for {CFG['PATIENCE']} epochs).\")\n",
    "        break\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df.to_csv(TABLE_DIR / \"training_history.csv\", index=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5,5.2))\n",
    "ax.plot(hist_df[\"epoch\"], hist_df[\"train\"], label=\"Train\")\n",
    "ax.plot(hist_df[\"epoch\"], hist_df[\"val\"],   label=\"Validation\")\n",
    "ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"MSE Loss\")\n",
    "ax.set_title(\"LSTM Convergence\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR / \"lstm_convergence.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "best_path.as_posix(), best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d871612-8613-452e-9421-d432fd8e884a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bh_mass</th>\n",
       "      <th>bh_acc</th>\n",
       "      <th>stellar_mass</th>\n",
       "      <th>sfr</th>\n",
       "      <th>halo_mass</th>\n",
       "      <th>vel_disp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H1</th>\n",
       "      <td>228.613199</td>\n",
       "      <td>141.974056</td>\n",
       "      <td>0.663351</td>\n",
       "      <td>0.288987</td>\n",
       "      <td>0.824576</td>\n",
       "      <td>1.404387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3</th>\n",
       "      <td>266.098185</td>\n",
       "      <td>96.950083</td>\n",
       "      <td>0.629554</td>\n",
       "      <td>0.089996</td>\n",
       "      <td>0.925593</td>\n",
       "      <td>1.499788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H5</th>\n",
       "      <td>290.478655</td>\n",
       "      <td>97.485360</td>\n",
       "      <td>0.686128</td>\n",
       "      <td>0.060783</td>\n",
       "      <td>1.090862</td>\n",
       "      <td>1.546049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bh_mass      bh_acc  stellar_mass       sfr  halo_mass  vel_disp\n",
       "H1  228.613199  141.974056      0.663351  0.288987   0.824576  1.404387\n",
       "H3  266.098185   96.950083      0.629554  0.089996   0.925593  1.499788\n",
       "H5  290.478655   97.485360      0.686128  0.060783   1.090862  1.546049"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_parquet(TEST_FP)\n",
    "\n",
    "\n",
    "assert 'BHTimeSeriesDataset' in globals(), \"Run Cell 2 first to define BHTimeSeriesDataset.\"\n",
    "dte = DataLoader(\n",
    "    BHTimeSeriesDataset(test_df, FEATURES, CFG[\"HORIZONS\"], STATS, CFG[\"T_IN\"]),\n",
    "    batch_size=CFG[\"BATCH\"], shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "\n",
    "ckpt = torch.load(MODEL_DIR/\"lstm_blackhole_best.pt\", map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sums = np.zeros((len(CFG[\"HORIZONS\"]), len(FEATURES)), dtype=np.float64)\n",
    "counts = np.zeros_like(sums)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in dte:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)     \n",
    "        yp = model(xb)                            \n",
    "        err2 = (yp - yb).pow(2).cpu().numpy()     \n",
    "        sums  += err2.sum(axis=0)\n",
    "        counts+= err2.shape[0]\n",
    "\n",
    "rmse = np.sqrt(sums / np.maximum(counts,1))\n",
    "rmse_df = pd.DataFrame(rmse, columns=FEATURES, index=[f\"H{h}\" for h in CFG[\"HORIZONS\"]])\n",
    "rmse_df.to_csv(TABLE_DIR/\"rmse_test_lstm.csv\")\n",
    "rmse_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7dc556d-21b6-4422-a7d9-1e0f7526f31b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('../reports/figures'), PosixPath('../reports/tables'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_preds(loader):\n",
    "    Y_list, P_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "            yp = model(xb)\n",
    "            Y_list.append(yb.cpu().numpy())\n",
    "            P_list.append(yp.cpu().numpy())\n",
    "    Y = np.concatenate(Y_list, axis=0)  \n",
    "    P = np.concatenate(P_list, axis=0)\n",
    "    return Y, P\n",
    "\n",
    "Yt, Pt = collect_preds(dte)\n",
    "h1 = 0\n",
    "\n",
    "\n",
    "for j, feat in enumerate(FEATURES):\n",
    "    y = Yt[:,h1,j].ravel()\n",
    "    p = Pt[:,h1,j].ravel()\n",
    "    lims = np.percentile(np.concatenate([y,p]), [1,99])\n",
    "    fig, ax = plt.subplots(figsize=(5.8,5.2))\n",
    "    ax.scatter(y, p, s=6, alpha=0.3)\n",
    "    ax.plot(lims, lims, lw=2)\n",
    "    ax.set_xlabel(f\"True {NAME_MAP[feat]} (z-scored)\")\n",
    "    ax.set_ylabel(f\"Predicted {NAME_MAP[feat]} (z-scored)\")\n",
    "    ax.set_title(f\"Parity (H=1) — {NAME_MAP[feat]}\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(FIG_DIR/f\"parity_H1_{feat}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "rmse_overall = [float(np.sqrt(((Yt[:,i,:]-Pt[:,i,:])**2).mean())) for i,_ in enumerate(CFG[\"HORIZONS\"])]\n",
    "fig, ax = plt.subplots(figsize=(6.6,4.8))\n",
    "ax.plot(CFG[\"HORIZONS\"], rmse_overall, marker=\"o\")\n",
    "ax.set_xlabel(\"Forecast Horizon (Δ snapshots)\")\n",
    "ax.set_ylabel(\"RMSE (z-scored, mean over features)\")\n",
    "ax.set_title(\"Error vs Horizon — LSTM\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR/\"rmse_vs_horizon_lstm.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "FIG_DIR, TABLE_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651e8cea-026a-49d9-b7f0-b933612fe935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('../reports/figures'), PosixPath('../reports/tables'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_persistence(X, Y):\n",
    "    last = X[:,-1:,:]                             \n",
    "    P = np.repeat(last, repeats=len(CFG[\"HORIZONS\"]), axis=1)\n",
    "    rmse = np.sqrt(((P - Y)**2).mean(axis=0))     \n",
    "    return rmse\n",
    "\n",
    "def baseline_ridge(X, Y, lam=1e-2):\n",
    "    B, T, F = X.shape\n",
    "    H = Y.shape[1]\n",
    "    Phi = X.reshape(B, T*F)\n",
    "    Phi_ = np.concatenate([Phi, np.ones((B,1),dtype=np.float32)], axis=1)  # bias\n",
    "    rmse = np.zeros((H,F), dtype=np.float32)\n",
    "    A = Phi_.T @ Phi_ + lam*np.eye(Phi_.shape[1], dtype=np.float32)\n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    for h in range(H):\n",
    "        Yh = Y[:,h,:]                              \n",
    "        W = np.zeros((F, Phi_.shape[1]), dtype=np.float32)\n",
    "        for j in range(F):\n",
    "            b = Phi_.T @ Yh[:,j:j+1]\n",
    "            w = (A_inv @ b).ravel()\n",
    "            W[j,:] = w\n",
    "        P = (Phi_ @ W.T)                           \n",
    "        rmse[h,:] = np.sqrt(((P - Yh)**2).mean(axis=0))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "Xt_list, Yt_list = [], []\n",
    "for xb, yb in dte:\n",
    "    Xt_list.append(xb.numpy()); Yt_list.append(yb.numpy())\n",
    "Xt = np.concatenate(Xt_list, axis=0)\n",
    "Yt_np = np.concatenate(Yt_list, axis=0)\n",
    "\n",
    "rmse_lstm = pd.read_csv(TABLE_DIR/\"rmse_test_lstm.csv\", index_col=0).values\n",
    "rmse_pers = baseline_persistence(Xt, Yt_np)\n",
    "rmse_ridge= baseline_ridge(Xt, Yt_np, lam=1e-2)\n",
    "\n",
    "pd.DataFrame(rmse_pers, columns=FEATURES, index=[f\"H{h}\" for h in CFG[\"HORIZONS\"]]).to_csv(TABLE_DIR/\"rmse_test_persistence.csv\")\n",
    "pd.DataFrame(rmse_ridge, columns=FEATURES, index=[f\"H{h}\" for h in CFG[\"HORIZONS\"]]).to_csv(TABLE_DIR/\"rmse_test_ridge.csv\")\n",
    "\n",
    "\n",
    "mean_lstm  = rmse_lstm.mean(axis=1)\n",
    "mean_pers  = rmse_pers.mean(axis=1)\n",
    "mean_ridge = rmse_ridge.mean(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.6,4.8))\n",
    "x = np.arange(len(CFG[\"HORIZONS\"]))\n",
    "ax.plot(x, mean_lstm,  marker=\"o\", label=\"LSTM\")\n",
    "ax.plot(x, mean_pers,  marker=\"o\", label=\"Persistence\")\n",
    "ax.plot(x, mean_ridge, marker=\"o\", label=\"Ridge\")\n",
    "ax.set_xticks(x); ax.set_xticklabels([f\"H{h}\" for h in CFG[\"HORIZONS\"]])\n",
    "ax.set_ylabel(\"RMSE (z-scored, mean over features)\")\n",
    "ax.set_title(\"Model Comparison vs Horizon\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR/\"model_comparison_rmse_vs_horizon.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "cmp_tbl = pd.DataFrame({\n",
    "    \"Horizon\": [f\"H{h}\" for h in CFG[\"HORIZONS\"]],\n",
    "    \"LSTM\": mean_lstm,\n",
    "    \"Persistence\": mean_pers,\n",
    "    \"Ridge\": mean_ridge\n",
    "})\n",
    "cmp_tbl.to_csv(TABLE_DIR/\"rmse_overall_by_horizon.csv\", index=False)\n",
    "\n",
    "FIG_DIR, TABLE_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34b733-1034-4daf-9cba-bca133440a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
